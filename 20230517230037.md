# Kalman u otras variables de lo mismo

## Modelo lineal gauss-markov

Analizando la bibliografía podemos hallar un antecedente cercano a la
formulación bayesiana del problema que estamos tratando. Se trata del
trabajo descripto en [@wuKALREFKalmanFilter2015] y analizado en
profundidad en [@abbondanzaSequentialEstimationApproach2020], que
plantean una solución a la determinación del marco de referencia
terrestre utilizando el filtro kalman y el suavizado RTS. Vale aclarar
que estos trabajos parten de la interpretación de cuadrados mínimos de
estos algoritmos, pero la formulación bayesiana queda implícita en su
modelo. Cabe mencionar además que este está entre los enfoques más
actuales y sirve de referencia y punto de comparación.

Para poder discutir las posibilidades de un enfoque bayesiano de este
problema, tomamos como referencia la solución implementada por
[@abbondanzaSequentialEstimationApproach2020], que utiliza el filtro
Kalman y el algoritmo de suavizado RTS. Es pertinente hacer aquí esta
comparación, porque el filtro Kalman es un estimador bayesiano, y es el
enfoque mas moderno de este problema. Para una referencia completa del
modelo se puede consultar [@wuKALREFKalmanFilter2015].

Para una referencia completa sobre el filtro kalman y el suavizado RTS
consultar el capítulo 4 de [@sarkkaBayesianFilteringSmoothing2013].
Baste aclarar aquí que, planteado un modelo lineal que describe la
observación número $k$ de un sistema como
$$Y_k=H\upbeta_k+\varepsilon_k,$$ siendo $H$ una matriz de dimensión
adecuada, $\upbeta$ y $Y|\upbeta$ procesos con distribucion gaussiana y
propiedad de markov, se puede resolver en forma exacta, mediante los
algoritmos de filtro de kalman y suavizado RTS respectivamente, las
distribuciones a-posteriori $P(\upbeta_k|y_{1:k})$, y
$P(\upbeta_k|y_{1:T})$, donde $k \in \{1,\ldots,T\}$.

### formulación del modelo

Se parte de una representación de espacio de estados de $X^i_k$, según
la cual:

$$\begin{aligned}
    X^i_{k+1} &= X^i_{k} + V^i_{k} (t_{k+1}-t_{k}) + f(S^i_{k},S^i_{k-1}) + \varepsilon^i_k\\
    V^i_{k+1} &= V^i_{k}\\
    S^i_{k+1} &= f(S^i_{k},S^i_{k-1}) \approx \cos(t_{k+1} 2\pi f_0+\phi_0)\\
    \Gamma_{k+1} &= \Gamma_k+\varepsilon^\Gamma_k
  \end{aligned}
\tag{\theequation}\label{kalman_base}$$ donde el vector de estados
$\upbeta_k$ se compone de $$X_k,V,S_{k},S_{k-1},\Gamma_k$$ resultando
$V$ velocidades constantes, y $S=\{S_0,S_1,\ldots,S_k\}$ señales
armónica observada en los tiempos $t_0,t_1,\ldots,t_k$,
$\Gamma_k:\{T_k,R_k,D_k\}$ parámetros de transformación de los sistemas
de coordendas y
$$\mathcal{E}^i_k \sim \mathcal{N}(0,\sigma^i);\quad\mathcal{E}^\Gamma_k \sim \mathcal{N}(0,\sigma^\Gamma),$$
de modo tal que para un sitio de observación $i$,
$$E^i_k =X^i_k - X^i_{0} - V^i (t_k) - S^i_k$$ es un movimiento
browniano, y algo similar ocurre con $\Gamma_k$.

Queda entonces para $\upbeta_k$ determinado que
$$\upbeta_k|\{\upbeta_{0},\ldots,\upbeta_{k-1}\} = \upbeta_k|\upbeta_{k-1}
\sim \mathcal{N}(U\beta_{k-1},\Sigma_{\beta,k})
\tag{\theequation}\label{kalman_cond_a}$$

Las posiciones observadas $y_k:\{{x^\star}^0_k,\ldots,{x^\star}^n_k\}$
de $n$ estaciones en la solución individual $k$, se modelan como

$$Y_k|\{\upbeta_0,\ldots,\upbeta_k\} = Y_k|\upbeta_k \sim \mathcal{N}(H\beta_k,\Sigma_k),
\tag{\theequation}\label{kalman_cond_b}$$

con $H$ una transformación lineal.

La principal diferencia de este modelo con
[\[mod_lineal_marco\]](#mod_lineal_marco){reference-type="eqref"
reference="mod_lineal_marco"} es la adición del proceso $E^i$ que tiene
covarianza temporal.

Las expresiones
[\[kalman_cond_a\]](#kalman_cond_a){reference-type="eqref"
reference="kalman_cond_a"} y
[\[kalman_cond_b\]](#kalman_cond_b){reference-type="eqref"
reference="kalman_cond_b"} describen un modelo lineal de gauss-markov,
sobre el que puede hacerse inferencia bayesiana para calcular las
distribuciones a-posteriori $P(\upbeta_k|y_{1:k})$, y
$P(\upbeta_k|y_{1:T})$.

### distribuciones a-priori del modelo

Los algoritmos para hacer inferencia sobre este modelo son iterativos y
parten de una distribución a priori de
$$\upbeta_0 \sim \mathcal{N}(\beta_0,\Sigma_0)$$, donde los parámetros
$\beta_0$ y $\Sigma_0$ son definidos por el usuario. Luego, en cada
iteración utiliza la observación $y_k$ y las matrices de covarianza
$\Sigma_{\beta,k}$ y $\Sigma_k$ de
[\[kalman_cond_a\]](#kalman_cond_a){reference-type="eqref"
reference="kalman_cond_a"} y
[\[kalman_cond_b\]](#kalman_cond_b){reference-type="eqref"
reference="kalman_cond_b"}.

En las implementaciones citadas, se utiliza la misma $\Sigma_{\beta,k}$
para todo $k$, con una estructura que supone independencia de cada
$X^i_k$. Para $\Sigma_k$ se utiliza $\Lambda_c^{-1}$ (ver sección
[2.3.2](#regulariza_sillard){reference-type="ref"
reference="regulariza_sillard"}). Nótese que esto último, tal como se
describió en secciones anteriores, implica suponer información a-priori
sobre la distribución de $\Gamma_k$.

### limitaciones de este modelo

Este modelo parte de fijar la distribución a-priori de $\upbeta_0$, y no
permite incluir explícitamente ningún tipo de conocimiento general sobre
la distribución general de $\upbeta$. Esto sería útil en los casos en
los que se necesita materializar un marco de referencia alineándolo a
otro, como cuando se trabaja a nivel regional. El modelo tampoco permite
parametrizar la covarinaza de las observaciones, lo cual sería de
utilidad para incluir en el modelo errores que en caso contrario deben
ser filtrados en pasos posteriores
[@dongSpatiotemporalFilteringUsing2006].

También es importante notar que se necesita hacer supuestos adicionales
para estimar la calidad con la que de los estimadores para $\upbeta_k$
se aproximan a $\upbeta$. (Ver [@wuKALREFKalmanFilter2015], sección 2.7)

En conclusión, si bien el modelo tiene una interpretación bayesiana,
sigue habiendo dificultades en cuanto al modelado de las covarianzas
espacio-temporales, y a las estimaciones de los errores asociados a los
parámetros del modelo, que podrían atacarse con otros modelos
bayesianos.
