# Cómo se expresan e interpretan las solciones.

## La naturaleza de las observaciones geodésicas

Las observaciones de posiciones geodésicas surgen de la resolución de
problemas inversos con gran cantidad de parámetros. La solución de estos
sistemas suele implementarse partiendo de valores aproximados,
utilizando versiones recursivas de mínimos cuadrados, filtro de Kalman o
alguna otra técnica de optimización. Independientemente del método que
se utilice para resolverlo, las posiciones calculadas se obtienen como
la solución de mínimos cuadrados de un problema lineal, $b = A x.$

Sea $x^\star$ una solución del problema de mínimos cuadrados
${\min}_{x}\|b-Ax\|^2_2$, y $\Lambda^\star:=A^T A$ (buscar nombre para
esta matriz). Observemos que, $x^\star$ es única si y sólo si
$\ker(\Lambda^*) = \{0\}$. En dicho caso, tenemos que
$$x^\star = \Sigma^\star A^T b,$$ donde
$\Sigma^\star:= {\Lambda^*}^{-1}$ y $\Lambda^*$ resulta ser la matriz de
precisión de $x^*$.

Sin embargo, por la naturaleza de las observaciones geodésicas, en
general $\ker(\Lambda^\star)\neq \{0\}$. En consecuencia, en lugar de
informar una solución del sistema, algunos centros de procesamiento
informan $\Lambda^\star$ y $A^T b$. (para mi esto no son las ecuaciones
normales)

Más frecuentemente, se considera la solución de mínimos cuadrados
generalizados, la cual resuelve mínimos cuadrados con la distancia de
Mahalanobis $\min_x \|b-Ax\|^2_{\Lambda_c}$. Como en el caso anterior,
tomando como $\Lambda^*:=A^T \Lambda_c A$, si
$\ker(\Lambda^*)\neq \{0\}$ la única solución de dicho problema es:
$$x^\star = \Sigma^\star A^T \Lambda_c b, \qquad \Sigma^\star:={\Lambda^*}^{-1}.$$

Esta versión generalizada puede obtenerse al suponerse cierta
dependencia entre los errores de las observaciones; más precisamente,
$$b + \varepsilon_b = A x, \qquad \varepsilon_b \sim \mathcal{N}_n(0, \Sigma_c), \quad \Sigma_c:=\Lambda_c^{-1}.
\tag{\theequation}\label{Priors-para-GLS}$$

### Indeterminación de las observaciones

Aún en el caso en que $\Lambda_\star$ no sea invertible, puede obtenerse
una solución al problema de mínimos cuadrados utilizando la
pseudo-inversa de Moore-Penrose y resulta ser, de todas las soluciones
posibles, aquella que minimiza la norma $L_2$. Sin embargo en el
contexto de marcos de referencia geodésicos debemos tener en cuenta que,
dado que la solución está compuesta por posiciones de puntos sobre la
tierra ($\simeq 6.4 \times 10^6 m$) y con variaciones del orden de los
centímetros o incluso menores ($\simeq 10^{-2}$), la minimización de
esta norma es un problema numéricamente inestable.

Aún si se obviaran las imprecisiones aritméticas, la indeterminación
causada por la orientación del sistema de coordenadas continua estando
presente.

## Regularización de las observaciones

Es por esto que, para regularizar el sistema de ecuaciones, debe
incluirse alguna clase de conocimiento previo sobre el mismo. Entre las
de mayor utilización, pueden encontrarse dos tipos de regularización.

Un método consiste en la regularización a partir de agregar ecuaciones
de posición de puntos seleccionados (modificando $A$ y $b$
correspondientemente), usando posiciones aproximadas. El otro método
consiste en operar sobre $\Lambda^\star$ para completar su rango.

### Regularización por ecuaciones agregadas

El primer método tiene efectos parecidos en el caso de la solución de
OLS y de GLS. Las ecuaciones para el caso de GLS (el más frecuentemente
utilizado) son:
$$b = \begin{bmatrix} b_{o} \\ b_{c} \end{bmatrix}, \qquad
A =\begin{bmatrix} A_{o}\\ A_{c} \end{bmatrix}, \qquad
\Sigma^{-1} = \begin{bmatrix} \Sigma^{-1}_{o} & 0 \\ 0 & \Sigma_{c}^{-1} \end{bmatrix}$$

$$\begin{aligned}
    {\Sigma^\star}^{-1} =&
    A^T \Sigma^{-1} A \\
    =& A^T_{o}\Sigma^{-1}_{o}A_{o} + A^T_{c} \Sigma_{c}^{-1} A_{c},\end{aligned}$$

$$\begin{aligned}
&x^\star = {\Sigma^*} A^T b \\
&=
(A^T_{o}\Sigma^{-1}_{o}A_{o} + A^T_{c} \Sigma_{c}^{-1} A_{c})^{-1}
(A^T_{o}\Sigma^{-1}_{o}b_{o} + A^T_{c} \Sigma_{c}^{-1} b_{c}),\end{aligned}$$

donde las letras $o$ y $c$ refieren a observaciones y regularización
respectivamente.

### Regularización descomponiendo el error en relativo al sistema de coordenadas e intrínseco {#regulariza_sillard}

En el contexto de GLS, la descomposición del error en un término
intrínseco a las observaciones y otro relativo al sistema de coordenadas
[@sillardReviewAlgebraicConstraints2001], se traduce en descomponer
$\Lambda_c$ en la suma de dos términos $\Psi$ y $\Xi$, obteniendo que
$$\label{GLS_sol_desc}
x^\star = (A^T\Psi A+A^T\Xi A)^{-1} (A^T\Psi b+A^T\Xi b),$$ donde
$\Psi=\Sigma_o^{-1}$, $\Xi= \mathcal{T}(\Sigma_{TRD}^{-1})$, siendo
$\mathcal{T}$ una transformación lineal, y $\Sigma_{TRD}$ una matriz de
covarianzas asociada a los parámetros de transformación entre el marco
de referencia de la solución individual y el combinado. La
transformación $\mathcal{T}$ se define a partir de la linealización de
una transformación de 7 o 14 parámetros aplicada sobre las coordenadas
aproximadas de los sitios de observación, según está detallado en
[@sillardReviewAlgebraicConstraints2001] (ecuación 8, sección 2.3)

La expresión [\[GLS_sol_desc\]](#GLS_sol_desc){reference-type="eqref"
reference="GLS_sol_desc"} puede expresarse en términos de la solución
del problema de mínimos cuadrados con regularización de Tikhonov
$\min_x \|b-Ax\|_{P}^{2}+\|x-x_{0}\|_{Q}^{2}$, que es

$$\label{tik_solution}
x^{*}=(A^{T}PA+Q)^{-1}(A^{T}Pb+Qx_{0}),$$ cuando se determinan
$$\label{GLS_Tikho}
P=\Psi, \quad Q=A^T\Xi A, \quad x_0=(A^T\Xi A)^{-1} A^T \Xi b.$$ Cabe
observar que $x_0 = \arg\min_x \|b-Ax\|_\Xi^2$, y puede interpretarse
como una solución de GLS, donde $\Sigma_c$ (ver
[\[Priors-para-GLS\]](#Priors-para-GLS){reference-type="eqref"
reference="Priors-para-GLS"}) contiene sólo información sobre los
errores que provienen de la indeterminación del sistema de coordenadas.

## Interpretación Bayesiana

Consideremos el modelo de regresión lineal bayesiana,
$$b_i = a_i^T X  + \varepsilon_i, \qquad i=1, \ldots, n,$$ cuya forma
matricial (conservando la notación de las secciones previas) es
$$b = A X + \mathcal{E}_b.$$

En el marco bayesiano, se agregan los siguientes supuestos:
$$X \sim \mathcal{N}_p(x_0, Q^{-1}), \qquad
\mathcal{E}_b \sim \mathcal{N}_n(0, P^{-1}),$$ siendo $X$ y
$\mathcal{E}_b$ independientes.

Observemos que el MAP de este modelo bayesiano queda en correspondencia
con la solución expresada en
[\[tik_solution\]](#tik_solution){reference-type="eqref"
reference="tik_solution"}. Esto, en vistas del vínculo expresado en la
subsección anterior (ver
[\[GLS_Tikho\]](#GLS_Tikho){reference-type="eqref"
reference="GLS_Tikho"}), nos da una interpretación bayesiana de los
métodos basados en GLS con regularización.

## Spectral SVD

Hay una interpretación de la regularización en función de spectral filtering methods. https://math.stackexchange.com/a/1363018
Ver capítulo 6 de Sciences of Geodesy-II (Xu 2013?)

https://link.springer.com/chapter/10.1007/978-3-642-28000-9_6?utm_source=getftr&utm_medium=getftr&utm_campaign=getftr_pilot

OJO, Notar que la pseudo-inversa de Moore-Penrose es Truncated SVD.
